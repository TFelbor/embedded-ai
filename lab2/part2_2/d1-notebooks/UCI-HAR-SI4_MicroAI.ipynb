{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI-HAR CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import test \n",
    "import train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load UCI-HAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_set(part: str):\n",
    "    data = np.hstack([np.loadtxt(Path(part)/'Inertial Signals'/f'{sensor}_{axis}_{part}.txt')\n",
    "                for sensor in ('body_acc', 'body_gyro', 'total_acc')\n",
    "                    for axis in ('x', 'y', 'z')]).reshape((-1, 128, 9))\n",
    "    labels = to_categorical(np.loadtxt(Path(part)/f'y_{part}.txt') - 1)\n",
    "    return data, labels\n",
    "\n",
    "x_train, y_train = load_set('train')\n",
    "x_test, y_test = load_set('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_250 = x_test[0:250]\n",
    "y_test_250 = y_test[0:250]\n",
    "np.savetxt('x_test_250.csv', x_test_250.reshape((x_test_250.shape[0], -1)), delimiter=',', fmt='%s')\n",
    "np.savetxt('y_test_250.csv', y_test_250, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7352 samples. Features: 128, Classes: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │        \u001b[38;5;34m18,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m54\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,638</span> (72.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,638\u001b[0m (72.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,638</span> (72.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,638\u001b[0m (72.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = x_train.shape[0]\n",
    "num_features = x_train.shape[1]\n",
    "num_classes = y_train.shape[1]  # Use one-hot encoded shape\n",
    "    \n",
    "print(f'Loaded {num_samples} samples. Features: {num_features}, Classes: {num_classes}')\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(num_features, 9)),\n",
    "    layers.Flatten(),  # Flatten 3D input to 1D\n",
    "    layers.Dense(16, activation='relu'),  # Hidden layer 1\n",
    "    layers.Dense(8, activation='relu'),   # Hidden layer 2 (helps with complexity)\n",
    "    layers.Dense(num_classes, activation='softmax') # Output layer\n",
    "])\n",
    "# EXPLORE Learning Rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=10e-3)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - categorical_accuracy: 0.6153 - loss: 0.9663 - val_categorical_accuracy: 0.5920 - val_loss: 1.0558\n",
      "Epoch 2/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - categorical_accuracy: 0.6153 - loss: 0.9663 - val_categorical_accuracy: 0.5920 - val_loss: 1.0558\n",
      "Epoch 2/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - categorical_accuracy: 0.7871 - loss: 0.5663 - val_categorical_accuracy: 0.8160 - val_loss: 0.4304\n",
      "Epoch 3/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - categorical_accuracy: 0.7871 - loss: 0.5663 - val_categorical_accuracy: 0.8160 - val_loss: 0.4304\n",
      "Epoch 3/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - categorical_accuracy: 0.8327 - loss: 0.4449 - val_categorical_accuracy: 0.7320 - val_loss: 0.6236\n",
      "Epoch 4/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - categorical_accuracy: 0.8327 - loss: 0.4449 - val_categorical_accuracy: 0.7320 - val_loss: 0.6236\n",
      "Epoch 4/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - categorical_accuracy: 0.8500 - loss: 0.4004 - val_categorical_accuracy: 0.7600 - val_loss: 0.6413\n",
      "Epoch 5/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - categorical_accuracy: 0.8500 - loss: 0.4004 - val_categorical_accuracy: 0.7600 - val_loss: 0.6413\n",
      "Epoch 5/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - categorical_accuracy: 0.8713 - loss: 0.3451 - val_categorical_accuracy: 0.7760 - val_loss: 0.5595\n",
      "Epoch 6/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - categorical_accuracy: 0.8713 - loss: 0.3451 - val_categorical_accuracy: 0.7760 - val_loss: 0.5595\n",
      "Epoch 6/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - categorical_accuracy: 0.8810 - loss: 0.3290 - val_categorical_accuracy: 0.7520 - val_loss: 0.5486\n",
      "Epoch 7/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - categorical_accuracy: 0.8810 - loss: 0.3290 - val_categorical_accuracy: 0.7520 - val_loss: 0.5486\n",
      "Epoch 7/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - categorical_accuracy: 0.8964 - loss: 0.2880 - val_categorical_accuracy: 0.6520 - val_loss: 0.9795\n",
      "Epoch 8/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - categorical_accuracy: 0.8964 - loss: 0.2880 - val_categorical_accuracy: 0.6520 - val_loss: 0.9795\n",
      "Epoch 8/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - categorical_accuracy: 0.9056 - loss: 0.2539 - val_categorical_accuracy: 0.6520 - val_loss: 0.8296\n",
      "Epoch 9/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - categorical_accuracy: 0.9056 - loss: 0.2539 - val_categorical_accuracy: 0.6520 - val_loss: 0.8296\n",
      "Epoch 9/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - categorical_accuracy: 0.9113 - loss: 0.2533 - val_categorical_accuracy: 0.7760 - val_loss: 0.5620\n",
      "Epoch 10/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - categorical_accuracy: 0.9113 - loss: 0.2533 - val_categorical_accuracy: 0.7760 - val_loss: 0.5620\n",
      "Epoch 10/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - categorical_accuracy: 0.9076 - loss: 0.2491 - val_categorical_accuracy: 0.7560 - val_loss: 0.7047\n",
      "Epoch 11/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - categorical_accuracy: 0.9076 - loss: 0.2491 - val_categorical_accuracy: 0.7560 - val_loss: 0.7047\n",
      "Epoch 11/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - categorical_accuracy: 0.9119 - loss: 0.2385 - val_categorical_accuracy: 0.7560 - val_loss: 0.6425\n",
      "Epoch 12/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - categorical_accuracy: 0.9119 - loss: 0.2385 - val_categorical_accuracy: 0.7560 - val_loss: 0.6425\n",
      "Epoch 12/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - categorical_accuracy: 0.9184 - loss: 0.2210 - val_categorical_accuracy: 0.7520 - val_loss: 0.9006\n",
      "Epoch 13/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - categorical_accuracy: 0.9184 - loss: 0.2210 - val_categorical_accuracy: 0.7520 - val_loss: 0.9006\n",
      "Epoch 13/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - categorical_accuracy: 0.9248 - loss: 0.2095 - val_categorical_accuracy: 0.5640 - val_loss: 1.4037\n",
      "Epoch 14/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - categorical_accuracy: 0.9248 - loss: 0.2095 - val_categorical_accuracy: 0.5640 - val_loss: 1.4037\n",
      "Epoch 14/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - categorical_accuracy: 0.9263 - loss: 0.2050 - val_categorical_accuracy: 0.7320 - val_loss: 0.8507\n",
      "Epoch 15/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - categorical_accuracy: 0.9263 - loss: 0.2050 - val_categorical_accuracy: 0.7320 - val_loss: 0.8507\n",
      "Epoch 15/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - categorical_accuracy: 0.9301 - loss: 0.1797 - val_categorical_accuracy: 0.6640 - val_loss: 0.9802\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - categorical_accuracy: 0.9301 - loss: 0.1797 - val_categorical_accuracy: 0.6640 - val_loss: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x316c0af90>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=15, validation_data=(x_test_250, y_test_250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - 3ms/step - categorical_accuracy: 0.6640 - loss: 0.9802\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "tf.Tensor(\n",
      "[[32 18  0  0  3  0]\n",
      " [ 0 25  0  0  0  0]\n",
      " [ 1  5 18  0  0  0]\n",
      " [ 0  0  3 11 32  0]\n",
      " [ 0 22  0  0 32  0]\n",
      " [ 0  0  0  0  0 48]], shape=(6, 6), dtype=int32)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "tf.Tensor(\n",
      "[[32 18  0  0  3  0]\n",
      " [ 0 25  0  0  0  0]\n",
      " [ 1  5 18  0  0  0]\n",
      " [ 0  0  3 11 32  0]\n",
      " [ 0 22  0  0 32  0]\n",
      " [ 0  0  0  0  0 48]], shape=(6, 6), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test_250, y_test_250, verbose=2)\n",
    "pred_test = model.predict(x_test_250)\n",
    "print(tf.math.confusion_matrix(y_test_250.argmax(axis=1), pred_test.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 - 0s - 746us/step - categorical_accuracy: 0.7974 - loss: 1.3102\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step\n",
      "tf.Tensor(\n",
      "[[355  65  47   6  23   0]\n",
      " [ 43 370  49   0   9   0]\n",
      " [ 16  25 371   3   5   0]\n",
      " [  3  22   8 389  69   0]\n",
      " [  8  58   3 108 355   0]\n",
      " [  0  18   9   0   0 510]], shape=(6, 6), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[355  65  47   6  23   0]\n",
      " [ 43 370  49   0   9   0]\n",
      " [ 16  25 371   3   5   0]\n",
      " [  3  22   8 389  69   0]\n",
      " [  8  58   3 108 355   0]\n",
      " [  0  18   9   0   0 510]], shape=(6, 6), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "pred_test = model.predict(x_test)\n",
    "print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('uci-har_si4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove SoftMax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │        \u001b[38;5;34m18,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m54\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37,278</span> (145.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m37,278\u001b[0m (145.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,638</span> (72.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,638\u001b[0m (72.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,640</span> (72.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m18,640\u001b[0m (72.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CORRECT way to remove Softmax but KEEP the layer weights\n",
    "model_without_softmax = tf.keras.models.clone_model(model)\n",
    "model_without_softmax.set_weights(model.get_weights())\n",
    "\n",
    "# Swap the last layer's activation from 'softmax' to 'linear' (which is nothing)\n",
    "model_without_softmax.layers[-1].activation = tf.keras.activations.linear\n",
    "\n",
    "# Save and Summary\n",
    "model_without_softmax.save('uci-har_si4_no_softmax.h5')\n",
    "model_without_softmax.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate C for the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected model.h generated!\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# CORRECTED C GENERATION SCRIPT (Fixed-Point + Transpose)\n",
    "# ---------------------------------------------------------\n",
    "import numpy as np\n",
    "\n",
    "# 1. Config\n",
    "FIXED_POINT = 9\n",
    "SCALE = 2 ** FIXED_POINT\n",
    "\n",
    "c_code = \"\"\"\n",
    "#ifndef MODEL_H\n",
    "#define MODEL_H\n",
    "#include <stdint.h>\n",
    "\n",
    "#define FIXED_POINT 9\n",
    "#define MODEL_INPUT_SAMPLES 128\n",
    "#define MODEL_INPUT_CHANNELS 9\n",
    "#define MODEL_INPUT_TOTAL 1152 \n",
    "#define MODEL_OUTPUT_SAMPLES 6\n",
    "\n",
    "typedef int16_t number_t;\n",
    "typedef int32_t long_number_t;\n",
    "\n",
    "number_t clamp_to_number_t(long_number_t value) {\n",
    "    if (value > 32767) return 32767;\n",
    "    if (value < -32768) return -32768;\n",
    "    return (number_t)value;\n",
    "}\n",
    "\n",
    "number_t activation_relu(number_t value) {\n",
    "    if (value < 0) return 0;\n",
    "    return value;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# 2. Extract and Convert Weights\n",
    "# We expect 3 Dense layers: Dense(16) -> Dense(8) -> Dense(6)\n",
    "layers = [l for l in model_without_softmax.layers if 'dense' in l.name]\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "    w, b = layer.get_weights()\n",
    "    \n",
    "    # TRANSPOSE W: Convert from [Input][Output] -> [Output][Input]\n",
    "    # This makes the C code loop much faster and simpler\n",
    "    w = w.T \n",
    "    \n",
    "    # QUANTIZE: Scale by 512 (Fixed Point 9)\n",
    "    w_int = (w * SCALE).astype(np.int16)\n",
    "    b_int = (b * SCALE).astype(np.int16)\n",
    "    \n",
    "    # Write Weights\n",
    "    flat_w = w_int.flatten()\n",
    "    c_code += f'\\n// Layer {i} Weights ({w.shape})\\n'\n",
    "    c_code += f'const int16_t weights_{i*2}[] = {{\\n'\n",
    "    for j, val in enumerate(flat_w):\n",
    "        c_code += f'{val}, '\n",
    "        if (j+1) % 16 == 0: c_code += '\\n'\n",
    "    c_code += '};\\n'\n",
    "    \n",
    "    # Write Biases\n",
    "    c_code += f'\\n// Layer {i} Biases\\n'\n",
    "    c_code += f'const int16_t weights_{i*2+1}[] = {{\\n'\n",
    "    for val in b_int:\n",
    "        c_code += f'{val}, '\n",
    "    c_code += '};\\n'\n",
    "\n",
    "# 3. Write Inference Function\n",
    "c_code += \"\"\"\n",
    "// Temporary buffers\n",
    "number_t layer1_out[16]; \n",
    "number_t layer2_out[8];\n",
    "\n",
    "void cnn(number_t* input, number_t* output) {\n",
    "    // --- LAYER 1: Dense 16 ---\n",
    "    for (int i = 0; i < 16; i++) { \n",
    "        long_number_t acc = 0; \n",
    "        for (int j = 0; j < 1152; j++) { \n",
    "            acc += (long_number_t)input[j] * weights_0[i * 1152 + j];\n",
    "        }\n",
    "        acc = acc >> FIXED_POINT;\n",
    "        acc += weights_1[i];\n",
    "        layer1_out[i] = activation_relu(clamp_to_number_t(acc));\n",
    "    }\n",
    "\n",
    "    // --- LAYER 2: Dense 8 ---\n",
    "    for (int i = 0; i < 8; i++) { \n",
    "        long_number_t acc = 0;\n",
    "        for (int j = 0; j < 16; j++) { \n",
    "            acc += (long_number_t)layer1_out[j] * weights_2[i * 16 + j];\n",
    "        }\n",
    "        acc = acc >> FIXED_POINT;\n",
    "        acc += weights_3[i];\n",
    "        layer2_out[i] = activation_relu(clamp_to_number_t(acc));\n",
    "    }\n",
    "\n",
    "    // --- LAYER 3: Dense 6 (Output) ---\n",
    "    for (int i = 0; i < 6; i++) { \n",
    "        long_number_t acc = 0;\n",
    "        for (int j = 0; j < 8; j++) { \n",
    "            acc += (long_number_t)layer2_out[j] * weights_4[i * 8 + j];\n",
    "        }\n",
    "        acc = acc >> FIXED_POINT;\n",
    "        acc += weights_5[i];\n",
    "        output[i] = clamp_to_number_t(acc);\n",
    "    }\n",
    "}\n",
    "#endif\n",
    "\"\"\"\n",
    "\n",
    "with open('model.h', 'w') as f:\n",
    "    f.write(c_code)\n",
    "\n",
    "print(\"Corrected model.h generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
